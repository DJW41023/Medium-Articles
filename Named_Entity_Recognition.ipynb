{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Named Entity Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6GitxZaTZua",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "d3e7d204-870c-4a2a-c9f2-beeb032f60db"
      },
      "source": [
        "# install the FedTools package:\n",
        "!pip install FedTools\n",
        "\n",
        "# install chart studio (Plotly):\n",
        "!pip install chart-studio\n",
        "\n",
        "# import pandas and numpy for data wrangling:\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# from FedTools, import the MonetrayPolicyCommittee module to download statements:\n",
        "from FedTools import MonetaryPolicyCommittee\n",
        "\n",
        "# import spacy and displaycy for visualisation:\n",
        "import spacy\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()\n",
        "from spacy import displacy\n",
        "\n",
        "# import Counter for counting:\n",
        "from collections import Counter\n",
        "\n",
        "# import plotly for plotting:\n",
        "import plotly.graph_objects as go"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting FedTools\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/ed/538cb88d9eb08be4d7413a1f56243cfaeb261bb458c2a9587f3d137b61fd/FedTools-0.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from FedTools) (1.0.5)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.6/dist-packages (from FedTools) (0.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->FedTools) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas->FedTools) (1.18.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->FedTools) (2018.9)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4->FedTools) (4.6.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->FedTools) (1.15.0)\n",
            "Installing collected packages: FedTools\n",
            "Successfully installed FedTools-0.0.1\n",
            "Collecting chart-studio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/ce/330794a6b6ca4b9182c38fc69dd2a9cbff60fd49421cb8648ee5fee352dc/chart_studio-1.1.0-py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from chart-studio) (4.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from chart-studio) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from chart-studio) (1.15.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from chart-studio) (1.3.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->chart-studio) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->chart-studio) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->chart-studio) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->chart-studio) (3.0.4)\n",
            "Installing collected packages: chart-studio\n",
            "Successfully installed chart-studio-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waa2rVS6lBp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataset_parsing():\n",
        "  '''\n",
        "  This function calls the MonetaryPolicyCommittee module of the FedTools package\n",
        "  to collect FOMC Statements. These statements are parsed using SpaCy.\n",
        "\n",
        "  Inputs: N/A.\n",
        "\n",
        "  Outputs: dataset: a Pandas DataFrame which contains:\n",
        "\n",
        "  'FOMC_Statements' - original FOMC Statements downloaded by FedTools.\n",
        "  'tokenised_data' - tokenised FOMC Statements.\n",
        "  'lemmatised_data' - lematised FOMC Statements.\n",
        "  'part_of_speech' - part of speech tags from FOMC Statements.\n",
        "  'named_entities' - the named entities detected within the FOMC Statements.\n",
        "  'labels' - the corresponding labels associated with named_entities.\n",
        "  'number_of_labels' - a dictionary displaying the number of each label detected.\n",
        "  'items' - the number of times each item is detected within the FOMC Statements.\n",
        "\n",
        "  '''\n",
        "\n",
        "  # collect FOMC Statements into DataFrame called dataset:\n",
        "  dataset = MonetaryPolicyCommittee().find_statements()\n",
        "\n",
        "  # remove additional operators within the text:\n",
        "  for i in range(len(dataset)):\n",
        "    dataset.iloc[i,0] = dataset.iloc[i,0].replace('\\\\n','. ')\n",
        "    dataset.iloc[i,0] = dataset.iloc[i,0].replace('\\n',' ')\n",
        "    dataset.iloc[i,0] = dataset.iloc[i,0].replace('\\r',' ')\n",
        "    dataset.iloc[i,0] = dataset.iloc[i,0].replace('\\xa0',' ')\n",
        "\n",
        "  # initialise empty lists:\n",
        "  tokens = []\n",
        "  lemma = []\n",
        "  pos = []\n",
        "  ents = []\n",
        "  labels = []\n",
        "  count = []\n",
        "  items = []\n",
        "\n",
        "  # for each document in the pipeline:\n",
        "  for doc in nlp.pipe(dataset['FOMC_Statements'].astype('unicode').values, batch_size=50, n_threads=10):\n",
        "      # if the document is successfully parsed:\n",
        "      if doc.is_parsed:\n",
        "          # append various data to appropriate categories:\n",
        "          tokens.append([n.text for n in doc])\n",
        "          lemma.append([n.lemma_ for n in doc])\n",
        "          pos.append([n.pos_ for n in doc])\n",
        "          ents.append([n.text for n in doc.ents])\n",
        "          labels.append([n.label_ for n in doc.ents])\n",
        "          count.append(Counter([n.label_ for n in doc.ents]))\n",
        "          items.append(Counter([n.text for n in doc.ents]))\n",
        "\n",
        "      # if document parsing fails, return 'None' to maintain DataFrame dimensions:\n",
        "      else:\n",
        "          tokens.append(None)\n",
        "          lemma.append(None)\n",
        "          pos.append(None)\n",
        "          ents.append(None)\n",
        "          labels.append(None)\n",
        "          count.append(None)\n",
        "          items.append(None)\n",
        "\n",
        "  # now assign the lists columns within the dataframe:\n",
        "  dataset['tokenised_data'] = tokens\n",
        "  dataset['lemmatised_data'] = lemma\n",
        "  dataset['part_of_speech'] = pos\n",
        "  dataset['named_entities'] = ents\n",
        "  dataset['labels'] = labels\n",
        "  dataset['number_of_labels'] = count\n",
        "  dataset['items'] = items\n",
        "\n",
        "  return dataset"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MzwjLSCcKoP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_additional_information():\n",
        "  '''\n",
        "  This function generates additional information from the parsed documents, quantifying\n",
        "  the usage of specific named entities within FOMC Statements.\n",
        "\n",
        "  Inputs: N/A.\n",
        "\n",
        "  Outputs: dataset: a Pandas DataFrame which contains:\n",
        "\n",
        "  'person' - the number of times people are mentioned in each statement.\n",
        "  'date' - the number of times dates are mentioned within each statement.\n",
        "  'percent' - the number of times percentages are mentioned within each statement.\n",
        "  'time' - the number of times a time is mentioned within each statement.\n",
        "  'ordinal' - the number of times an 'ordinal' ie) \"first\" is mentioned within each statement.\n",
        "  'organisations' - the number of times an organisation is mentioned within each statement.\n",
        "  'money' - the number of times money is mentioned within each statement.\n",
        "  'event' - the number of times an event is mentioned within each statement.\n",
        "  'law' - the number of times a law is mentioned within each statement.\n",
        "  'quantity' - the number of times a quantity is mentioned within each statement.\n",
        "  'groups' - the number of times specific groups are mentioned within each statement.\n",
        "  'information_content' -  the number of named entities detected within each statement.\n",
        "\n",
        "  '''\n",
        "  # call the function defined above:\n",
        "  dataset = dataset_parsing()\n",
        "\n",
        "  # generate additional information through the detection of named entities:\n",
        "  dataset['person'] = dataset['number_of_labels'].apply(lambda x: x.get('PERSON'))\n",
        "  dataset['date'] = dataset['number_of_labels'].apply(lambda x: x.get('DATE'))\n",
        "  dataset['percent'] = dataset['number_of_labels'].apply(lambda x: x.get('PERCENT'))\n",
        "  dataset['product'] = dataset['number_of_labels'].apply(lambda x: x.get('PRODUCT'))\n",
        "  dataset['time'] = dataset['number_of_labels'].apply(lambda x: x.get('TIME'))\n",
        "  dataset['ordinal'] = dataset['number_of_labels'].apply(lambda x: x.get('ORDINAL'))\n",
        "  dataset['organisations'] = dataset['number_of_labels'].apply(lambda x: x.get('ORG'))\n",
        "  dataset['money'] = dataset['number_of_labels'].apply(lambda x: x.get('MONEY'))\n",
        "  dataset['event'] = dataset['number_of_labels'].apply(lambda x: x.get('EVENT'))\n",
        "  dataset['law'] = dataset['number_of_labels'].apply(lambda x: x.get('LAW'))\n",
        "  dataset['quantity'] = dataset['number_of_labels'].apply(lambda x: x.get('QUANTITY'))\n",
        "  dataset['groups'] = dataset['number_of_labels'].apply(lambda x: x.get('NORP'))\n",
        "\n",
        "  # replace any 'NaN' values with 0, then calculate the 'information content',as defined\n",
        "  # by the total number of named entities:\n",
        "  dataset = dataset.replace(np.nan, 0)\n",
        "  dataset['information_content'] = dataset.iloc[:,8:].sum(axis = 1)\n",
        "\n",
        "  return dataset"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szrlQE5P9pm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_chairperson(dataset):\n",
        "  '''\n",
        "  This function uses Named Entity Recognition in order to detect the presence of \n",
        "  chairpeople within the FOMC statements. \n",
        "\n",
        "  Inputs: dataset: a Pandas DataFrame as defined above.\n",
        "\n",
        "  Outputs: dataset: a Pandas DataFrame which identifies the FOMC Chairperson.\n",
        "  '''\n",
        "\n",
        "  # try to detect specific names within 'items':\n",
        "  dataset['Greenspan'] = dataset['items'].apply(lambda x: x.get('Alan Greenspan'))\n",
        "  dataset['Bernanke'] = dataset['items'].apply(lambda x: x.get('Ben S. Bernanke'))\n",
        "  dataset['Yellen'] = dataset['items'].apply(lambda x: x.get('Janet L. Yellen'))\n",
        "  dataset['Powell'] = dataset['items'].apply(lambda x: x.get('Jerome H. Powell'))\n",
        "\n",
        "  # replace all 'Nan' values with 0:\n",
        "  dataset = dataset.replace(np.nan, 0)\n",
        "\n",
        "  return dataset"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi27TylbhLeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_figure():\n",
        "  '''\n",
        "  This function constructs a Plotly chart by calling the above functions to generate\n",
        "  the dataset, and subsequently plotting relevant data. \n",
        "  '''\n",
        "\n",
        "  # define the dataset as a global variable, which can be used outside of the function:\n",
        "  global dataset\n",
        "  # call the above functions to generate the required data:\n",
        "  dataset = generate_additional_information()\n",
        "  dataset = generate_chairperson(dataset)\n",
        "\n",
        "  # initialise figure:\n",
        "  fig = go.Figure()\n",
        "\n",
        "  # add figure traces:\n",
        "  fig.add_trace(go.Scatter(x = dataset.index, y = dataset['information_content'],\n",
        "                           mode = 'lines',\n",
        "                           name = 'Information Content',\n",
        "                           connectgaps=True))\n",
        "  \n",
        "  fig.add_trace(go.Scatter(x = dataset.index, y = dataset['percent'],\n",
        "                           mode = 'lines',\n",
        "                           name = 'Number of times \"Percentage\" mentioned',\n",
        "                           connectgaps=True))\n",
        "  \n",
        "  fig.add_trace(go.Scatter(x = dataset.index, y = dataset['person'],\n",
        "                           mode = 'lines',\n",
        "                           name = 'Number of People mentioned',\n",
        "                           connectgaps=True))\n",
        "  \n",
        "  fig.add_trace(go.Scatter(x = dataset.index, y = dataset['money'],\n",
        "                           mode = 'lines',\n",
        "                           name = 'Number of times Money mentioned',\n",
        "                           connectgaps=True))\n",
        "  \n",
        "  fig.add_trace(go.Scatter(x = dataset.index, y = dataset['quantity'],\n",
        "                           mode = 'lines',\n",
        "                           name = 'Number of Quantities mentioned',\n",
        "                           connectgaps=True))\n",
        "  \n",
        "  fig.add_trace(go.Scatter(x = dataset.index, y = dataset['event'],\n",
        "                           mode = 'lines',\n",
        "                           name = 'Number of Events mentioned',\n",
        "                           connectgaps=True))\n",
        "  \n",
        "  fig.add_trace(go.Scatter(x = dataset.index, y = dataset['organisations'],\n",
        "                           mode = 'lines',\n",
        "                           name = 'Number of Organisations mentioned',\n",
        "                           connectgaps=True))\n",
        "\n",
        "  # add a rangeslider and buttons:\n",
        "  fig.update_xaxes(\n",
        "    rangeslider_visible=True,\n",
        "    rangeselector=dict(\n",
        "        buttons=list([\n",
        "            dict(count=1, label=\"YTD\", step=\"year\", stepmode=\"todate\"),\n",
        "            dict(count=5, label=\"5 Years\", step=\"year\", stepmode=\"backward\"),\n",
        "            dict(count=10, label=\"10 Years\", step=\"year\", stepmode=\"backward\"),\n",
        "            dict(count=15, label=\"15 Years\", step=\"year\", stepmode=\"backward\"),\n",
        "            dict(label=\"All\", step=\"all\")\n",
        "        ]))) \n",
        "\n",
        "  # add a chart title and axis title:\n",
        "  fig.update_layout(\n",
        "    title=\"FOMC Named Entity Recognition\",\n",
        "    xaxis_title=\"Date\",\n",
        "    yaxis_title=\"\",\n",
        "    font=dict(\n",
        "        family=\"Arial\",\n",
        "        size=11,\n",
        "        color=\"#7f7f7f\"\n",
        "    ))\n",
        "  \n",
        "  # add toggle buttons for dataset display:\n",
        "  fig.update_layout(\n",
        "      updatemenus=[\n",
        "          dict(\n",
        "            buttons=list([\n",
        "                  dict(\n",
        "                    label = 'All',\n",
        "                    method = 'update',\n",
        "                    args = [{'visible': [True, True, True, True, True, True, True]}]\n",
        "                  ),\n",
        "\n",
        "                  dict(\n",
        "                    label = 'Information Content',\n",
        "                    method = 'update',\n",
        "                    args = [{'visible': [True, False, False, False, False, False, False]}]\n",
        "                  ),\n",
        "\n",
        "                  dict(\n",
        "                    label = 'Percentage mentions',\n",
        "                    method = 'update',\n",
        "                    args = [{'visible': [False, True, False, False, False, False, False,]}]\n",
        "                  ),\n",
        "\n",
        "                  dict(\n",
        "                    label = 'People mentions',\n",
        "                    method = 'update',\n",
        "                    args = [{'visible': [False, False, True, False, False, False, False,]}]\n",
        "                  ),\n",
        "\n",
        "                  dict(\n",
        "                    label = 'Money mentions',\n",
        "                    method = 'update',\n",
        "                    args = [{'visible': [False, False, False, True, False, False, False,]}]\n",
        "                  ),\n",
        "\n",
        "                  dict(\n",
        "                    label = 'Quantity mentions',\n",
        "                    method = 'update',\n",
        "                    args = [{'visible': [False, False, False, False, True, False, False,]}]\n",
        "                  ),\n",
        "\n",
        "                  dict(\n",
        "                    label = 'Event mentions',\n",
        "                    method = 'update',\n",
        "                    args = [{'visible': [False, False, False, False, False, True, False,]}]\n",
        "                  ),\n",
        "\n",
        "                  dict(\n",
        "                    label = 'Organisation mentions',\n",
        "                    method = 'update',\n",
        "                    args = [{'visible': [False, False, False, False, False, False, True]}]\n",
        "                  ),\n",
        "              ]),\n",
        "              direction=\"down\",\n",
        "              pad={\"r\": 10, \"t\": 10},\n",
        "              showactive=True,\n",
        "              x=1.0,\n",
        "              xanchor=\"right\",\n",
        "              y=1.2,\n",
        "              yanchor=\"top\"\n",
        "          ),])\n",
        "  \n",
        "  return fig.show()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJP1Z2iVHruM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_figure()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe3xyHvS3OwG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now visualise the named entities detected within specific FOMC Statements:\n",
        "displacy.render(nlp(dataset['FOMC_Statements'][103]), jupyter = True, style = 'ent')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}